# Structure-Factorized Attention (SFA) for Document-Centric Multimodal LLMs

## ë°œí‘œìë£Œ

---

## 1. ì—°êµ¬ ë°°ê²½ ë° ë¬¸ì œ ì •ì˜

### ê¸°ì¡´ Vision Encoderì˜ í•œê³„

í˜„ì¬ ëŒ€ë¶€ë¶„ì˜ ë©€í‹°ëª¨ë‹¬ LLM (InternVL, Qwen-VL, LLaVA ë“±)ì€ **ViT ê¸°ë°˜ vision encoder**ë¥¼ ì‚¬ìš©.

**ë¬¸ì œì :**

- **Uniform Patch Tokenization**: ë¬¸ì„œ ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ë°€ì§‘ ì˜ì—­ê³¼ ë¹ˆ ê³µê°„ì— ë™ì¼í•œ í¬ê¸°ì˜ íŒ¨ì¹˜ ì ìš©
  - í…ìŠ¤íŠ¸ ì˜ì—­: ì •ë³´ê°€ ê³¼ë„í•˜ê²Œ ì••ì¶• â†’ ì‘ì€ ìˆ«ì/í…ìŠ¤íŠ¸ ì¸ì‹ ì˜¤ë¥˜
  - ë¹ˆ ê³µê°„: ë¶ˆí•„ìš”í•œ í† í° ë‚­ë¹„

- **Layout Inductive Bias ë¶€ì¬**: ViTì˜ positional encodingì€ ë¬¸ì„œì˜ í–‰/ì—´/ë¸”ë¡ êµ¬ì¡°ë¥¼ ë°˜ì˜í•˜ì§€ ëª»í•¨

- **ìˆ«ì Hallucination**: ì°¨íŠ¸/í‘œì—ì„œ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ìˆ«ìë¥¼ ìƒì„±í•˜ëŠ” ë¬¸ì œê°€ ì‹¬ê°

### í•µì‹¬ ì—°êµ¬ ì§ˆë¬¸

> ë¬¸ì„œ ì´ë¯¸ì§€ì˜ **êµ¬ì¡°ì  íŠ¹ì„±**ì„ vision encoderì˜ attentionì— ì§ì ‘ ì£¼ì…í•˜ë©´,
> groundingì´ ì•ˆì •í™”ë˜ê³  hallucinationì´ ì¤„ì–´ë“œëŠ”ê°€?

---

## 2. Baseline ë¶„ì„ ê²°ê³¼

### ì‹¤í—˜ í™˜ê²½

| í•­ëª© | ê°’ |
|------|-----|
| Base Model | InternVL3.5-8B |
| Vision Encoder | InternViT-300M-448px (24 layers) |
| LLM | InternLM2.5-7B-Chat |
| GPU | NVIDIA A100-PCIE-40GB Ã— 2 |
| í‰ê°€ ë²¤ì¹˜ë§ˆí¬ | ChartQA (Relaxed Accuracy) |

### Baseline ì„±ëŠ¥

| Metric | Score |
|--------|-------|
| **ChartQA Relaxed Accuracy** | **0.620** |

### Hallucination ë¶„ì„ (200 samples)

| ë¶„ë¥˜ | ìˆ˜ | ë¹„ìœ¨ |
|------|-----|------|
| ì •ë‹µ | 130 | 65.0% |
| **ìˆ«ì Hallucination** | **51** | **25.5%** |
| ì˜¤ë‹µ (ê¸°íƒ€) | 19 | 9.5% |

> **ì˜¤ë¥˜ì˜ 73%ê°€ ìˆ«ì hallucination** â€” ì´ë¯¸ì§€ì— ì—†ëŠ” ìˆ«ìë¥¼ ìƒì„±

### ì˜¤ë‹µ ì˜ˆì‹œ

| Question | GT | Prediction | ì˜¤ë¥˜ ìœ í˜• |
|----------|-----|-----------|-----------|
| "What was the largest dark red bar value?" | 0.08 | **26** | ìˆ«ì hallucination |
| "What is the difference between highest and lowest?" | 54 | **99** | ìˆ«ì hallucination |
| "What's the value for the rightmost bar?" | 0.57 | **10.04** | ìë¦¿ìˆ˜ ì˜¤ë¥˜ |

### Attention Entropy ë¶„ì„

| ì˜ì—­ | Entropy | ì°¨ì´ |
|------|---------|------|
| Text-dense region | 4.3322 | - |
| Sparse region | 4.4377 | - |
| **ë¹„ìœ¨** | **0.98x** | â‰ˆ ë™ì¼ |

> Text-dense/sparse ê°„ attention entropy ì°¨ì´ê°€ ê±°ì˜ ì—†ìŒ
> â†’ **Vision encoderê°€ ë¬¸ì„œ êµ¬ì¡°ë¥¼ êµ¬ë¶„í•˜ì§€ ëª»í•¨** â†’ SFA í•„ìš”ì„± ì…ì¦

---

## 3. ì œì•ˆ ë°©ë²•: Structure-Factorized Attention (SFA)

### í•µì‹¬ ì•„ì´ë””ì–´

ê¸°ì¡´ ViT self-attentionì— **ë¬¸ì„œ êµ¬ì¡° bias**ë¥¼ ì¶”ê°€:

```
ê¸°ì¡´:  S_ij = (Q_i Â· K_j^T) / âˆšd

ì œì•ˆ:  S_ij = (Q_i Â· K_j^T) / âˆšd  +  Ï†(s_i, s_j)
              â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€     â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
               Content Attention    Structural Bias
```

### Structural Bias Ï†(s_i, s_j) êµ¬ì„±

```
Ï† = w_row Â· ğŸ™[row_i = row_j]           â† ê°™ì€ í–‰ íŒ¨ì¹˜ ê°„ ê°•í™”
  + w_col Â· ğŸ™[col_i = col_j]           â† ê°™ì€ ì—´ íŒ¨ì¹˜ ê°„ ê°•í™”
  + w_dist Â· (-manhattan(i,j))          â† ê°€ê¹Œìš´ íŒ¨ì¹˜ ê°„ ê°•í™”
  + block_embed(b_i)^T Â· block_embed(b_j)  â† ê°™ì€ ë¸”ë¡ ê°„ ê°•í™”
```

### íŒŒë¼ë¯¸í„° íš¨ìœ¨ì„±

| Component | Parameters | Overhead |
|-----------|-----------|----------|
| w_row (per head) | 16 | - |
| w_col (per head) | 16 | - |
| w_dist (per head) | 16 | - |
| block_embed (16 blocks Ã— 16 heads) | 256 | - |
| **Layerë‹¹ í•©ê³„** | **304** | **0.007%** |
| **ì „ì²´ (24 layers)** | **7,296** | **0.002%** |

> ì „ì²´ ëª¨ë¸ ëŒ€ë¹„ **0.002%ì˜ íŒŒë¼ë¯¸í„°**ë§Œ ì¶”ê°€í•˜ë©´ì„œ êµ¬ì¡°ì  inductive bias ì œê³µ

### ì ìš© ë°©ì‹

- InternViTì˜ **24ê°œ attention layer ëª¨ë‘**ì— SFA ì ìš©
- CLS í† í°ì—ëŠ” structural bias ë¯¸ì ìš© (spatial tokensë§Œ)
- Pretrained QKV weights ìœ ì§€, structural biasë§Œ small init (std=0.02)

---

## 4. Adaptive Density-Aware Tokenization (ADAT)

### ë™ê¸°

ë¬¸ì„œ ì´ë¯¸ì§€ì—ì„œ:
- í…ìŠ¤íŠ¸ ë°€ì§‘ ì˜ì—­ â†’ ë” ì‘ì€ íŒ¨ì¹˜ í•„ìš” (ë†’ì€ í•´ìƒë„)
- ë¹ˆ ê³µê°„ â†’ í° íŒ¨ì¹˜ë¡œ ì¶©ë¶„ (í† í° ì ˆì•½)

### Text Density Estimator

| í•­ëª© | ê°’ |
|------|-----|
| Architecture | 6-layer CNN |
| Parameters | **186K** (ê²½ëŸ‰) |
| Input | 448Ã—448 document image |
| Output | 28Ã—28 density heatmap D(x,y) âˆˆ [0,1] |
| Training | Self-supervised (pseudo labels) |
| Val Loss | **0.001728** |

### Pseudo Label ìƒì„±

```
Document Image â†’ Canny Edge Detection â†’ Adaptive Threshold â†’ Gaussian Blur â†’ Density Map
```

ë³„ë„ annotation ì—†ì´ ì´ë¯¸ì§€ ìì²´ì—ì„œ í…ìŠ¤íŠ¸ ë°€ë„ ì¶”ì • ê°€ëŠ¥

### Adaptive Patch ì „ëµ (ê³„íš)

| Density | Patch Size | í† í° ìˆ˜ |
|---------|-----------|---------|
| D > 0.7 (high) | 8Ã—8 | ë§ìŒ (ì„¸ë°€) |
| 0.3 < D â‰¤ 0.7 (medium) | 14Ã—14 | í‘œì¤€ |
| D â‰¤ 0.3 (low) | 32Ã—32 | ì ìŒ (íš¨ìœ¨) |

---

## 5. í•™ìŠµ ì „ëµ ë° OOM í•´ê²°

### í•™ìŠµ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Trainable (4.0%)                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ InternViT-300M   â”‚  â”‚ MLP Projector    â”‚     â”‚
â”‚  â”‚ + SFA (24 layers)â”‚â†’â”‚ (4096â†’4096)      â”‚     â”‚
â”‚  â”‚ GPU 0: 8.1 GB    â”‚  â”‚                  â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                 â”‚               â”‚
â”‚  Frozen (96.0%)                 â–¼               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ InternLM2.5-7B-Chat (bf16)              â”‚   â”‚
â”‚  â”‚ GPU 1: 15.3 GB                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### OOM ë¬¸ì œ ë° í•´ê²°

**ë¬¸ì œ**: InternVL3.5-8B (17GB bf16)ì„ A100-40GBì—ì„œ fine-tuning ì‹œ OOM

**í•´ê²° (2-GPU Model Parallel):**

| ì „ëµ | ë‚´ìš© | íš¨ê³¼ |
|------|------|------|
| Vision â†’ GPU 0 | Vision encoder + projector (trainable) | 8.1 GB |
| LLM â†’ GPU 1 | LLM (frozen, bf16 full) | 15.3 GB |
| Gradient Checkpointing | Vision encoder í™œì„±í™” ë©”ëª¨ë¦¬ ì ˆê° | -50% activation |
| batch_size=4 | GPU ì—¬ìœ  í™œìš© | ì²˜ë¦¬ëŸ‰ 4ë°°â†‘ |

**ì´ì „ ì‹œë„ (ì‹¤íŒ¨):**
- Single GPU full bf16 â†’ OOM (17GB + optimizer + activations > 40GB)
- DDP 2-GPU â†’ ê° rankë§ˆë‹¤ full model ë³µì‚¬ â†’ OOM

---

## 6. í˜„ì¬ í•™ìŠµ ì§„í–‰ ìƒí™©

### í•™ìŠµ ì„¤ì •

| í•­ëª© | ê°’ |
|------|-----|
| Data | ChartQA train (28,299 samples) |
| Effective batch size | 4 Ã— 8 (grad_accum) = **32** |
| Epochs | 3 |
| Optimizer | AdamW (lr=2e-5, cosine schedule) |
| Total optimizer steps | 2,652 |

### Loss ì¶”ì´

```
Epoch 1:
  step   80 | loss: 4.7813  â† ì´ˆê¸°
  step  400 | loss: 4.3514
  step 2000 | loss: 1.3860
  step 7074 | loss: 1.1015  â† Epoch 1 ì™„ë£Œ

Epoch 2:
  step   80 | loss: 0.6696
  step 2000 | loss: 0.5361
  step 6880 | loss: 0.5087  â† í˜„ì¬ ì§„í–‰ ì¤‘

Epoch 3: (ì§„í–‰ ì˜ˆì •)
```

> **Loss: 4.78 â†’ 0.51 (ì•½ 90% ê°ì†Œ)** â€” í•™ìŠµ ì •ìƒ ìˆ˜ë ´ ì¤‘

### GPU í™œìš©ë¥ 

| GPU | ì—­í•  | ë©”ëª¨ë¦¬ ì‚¬ìš© | ì—¬ìœ  |
|-----|------|-----------|------|
| GPU 0 | Vision (trainable) | 8.1 GB | 32.9 GB (80%) |
| GPU 1 | LLM (frozen) | 15.3 GB | 25.7 GB (63%) |

---

## 7. ë…¼ë¬¸ Figure ìƒì„± í˜„í™©

### Figure 1: Motivation (âœ… ì™„ë£Œ)

3-panel êµ¬ì„±:
- (a) Uniform 14Ã—14 grid â†’ ëª¨ë“  ì˜ì—­ì— ë™ì¼ íŒ¨ì¹˜
- (b) Density heatmap â†’ í…ìŠ¤íŠ¸ ë°€ì§‘ ì˜ì—­ ì‹œê°í™”
- (c) Adaptive patching â†’ ë°€ì§‘ ì˜ì—­ì— ë” ì„¸ë°€í•œ íŒ¨ì¹˜

### Figure 2: Architecture Diagram (âœ… ì™„ë£Œ)

ì „ì²´ íŒŒì´í”„ë¼ì¸: Input â†’ Density Estimator â†’ Adaptive Tokenization â†’ ViT + SFA â†’ Projector â†’ LLM â†’ Output

### Figure 5: Entropy Analysis (âœ… Baseline ì™„ë£Œ)

- Violin plot: text-dense vs sparse region entropy ë¶„í¬
- Layer-wise line plot: ê° layerì˜ entropy ë³€í™”

â†’ SFA í•™ìŠµ í›„ ë¹„êµ ë°ì´í„° ì¶”ê°€ ì˜ˆì •

---

## 8. ì‹¤í—˜ íŒŒì´í”„ë¼ì¸ ì „ì²´ êµ¬ì¡°

```
Phase 0: Baseline â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âœ… ì™„ë£Œ
  â””â†’ ChartQA Acc=0.620, Halluc=25.5%

Phase 1: ì‹œê°í™” ìŠ¤í¬ë¦½íŠ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ âœ… ì™„ë£Œ
  â””â†’ Figure 1, 3, 5 ìŠ¤í¬ë¦½íŠ¸ + Baseline ìƒì„±

Phase 2: SFA Fine-tuning â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ğŸ”„ ì§„í–‰ ì¤‘
  â”œâ†’ P2-1: ìŠ¤í¬ë¦½íŠ¸ êµ¬í˜„ âœ…
  â”œâ†’ P2-2: í•™ìŠµ ì‹¤í–‰   ğŸ”„ (Epoch 2/3)
  â”œâ†’ P2-3: ChartQA eval â†’ Table 1 "+SFA"
  â”œâ†’ P2-4: Entropy ì¬ì¸¡ì • â†’ Figure 5 ì™„ì„±
  â”œâ†’ P2-5: Hallucination ì¬ì¸¡ì • â†’ Table 2
  â”œâ†’ P2-6: Attention heatmap â†’ Figure 3 ì™„ì„±
  â”œâ†’ P2-7: Structural bias ì‹œê°í™” â†’ Figure 7
  â””â†’ P2-8: Component ablation â†’ Table 3

Phase 3: ADAT êµ¬í˜„ + í†µí•© â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â¬œ ì˜ˆì •
  â””â†’ Adaptive tokenization + Token efficiency ì‹¤ì¸¡

Phase 4: Full System (SCR) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â¬œ ì˜ˆì •
  â””â†’ Entropy/Grounding/Stability loss â†’ Hallucination ê°ì†Œ

Phase 5: Cross-Architecture + ë…¼ë¬¸ â”€â”€â”€â”€â”€â”€ â¬œ ì˜ˆì •
  â”œâ†’ SFA â†’ Qwen2.5-VL (SigLIP+Qwen) ì ìš©
  â”œâ†’ SFA â†’ LLaVA-OV (CLIP+LLaMA) ì ìš©
  â””â†’ ë…¼ë¬¸ ì‘ì„±
```

---

## 9. ê¸°ëŒ€ ê¸°ì—¬ì 

1. **Structure-Factorized Attention**: 0.002% íŒŒë¼ë¯¸í„° ì¶”ê°€ë¡œ ë¬¸ì„œ êµ¬ì¡° ì¸ì‹ ê°•í™”
2. **Adaptive Density-Aware Tokenization**: ë™ì¼ í† í° ìˆ˜ì—ì„œ ì •ë³´ëŸ‰ ê·¹ëŒ€í™”
3. **Hallucination ê°ì†Œ**: Attention entropy ê°ì†Œ + ìˆ«ì grounding ì•ˆì •í™”
4. **Architecture-Agnostic**: InternViT/SigLIP/CLIP ë“± ë‹¤ì–‘í•œ ViTì— ì ìš© ê°€ëŠ¥
5. **ë‹¤êµ­ì–´ ì¼ë°˜í™”**: í•œêµ­ì–´(AIDA, AIHUB) + ì˜ì–´(ChartQA, DocVQA) ë™ì‹œ ê²€ì¦

---

## 10. íƒ€ì„ë¼ì¸

| ê¸°ê°„ | ì‘ì—… | ìƒíƒœ |
|------|------|------|
| 2/20 | Baseline ë¶„ì„ + Density Estimator + SFA ëª¨ë“ˆ | âœ… ì™„ë£Œ |
| 2/20 | SFA í†µí•© + Entropy/Hallucination ë¶„ì„ | âœ… ì™„ë£Œ |
| 2/23 | OOM í•´ê²° + 2-GPU í•™ìŠµ ì‹œì‘ | âœ… ì™„ë£Œ |
| 2/23~24 | SFA í•™ìŠµ ì™„ë£Œ + í›„ì† ë¶„ì„ | ğŸ”„ ì§„í–‰ ì¤‘ |
| 2/24~25 | ADAT êµ¬í˜„ + SFA+ADAT í†µí•© | â¬œ ì˜ˆì • |
| 2/25~26 | Full System (SCR) í•™ìŠµ | â¬œ ì˜ˆì • |
| 2/27~28 | Cross-Architecture ì‹¤í—˜ | â¬œ ì˜ˆì • |
| 3/1~ | ë…¼ë¬¸ ì‘ì„± | â¬œ ì˜ˆì • |

---

## Appendix: ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­

### SFA ìˆ˜ì‹ ìƒì„¸

32Ã—32 grid (1024 spatial tokens) + 1 CLS token = 1025 tokens

Precomputed buffers (í•™ìŠµ ì¤‘ ê³ ì •):
- `same_row[i,j]`: íŒ¨ì¹˜ i, jê°€ ê°™ì€ í–‰ì´ë©´ 1, ì•„ë‹ˆë©´ 0
- `same_col[i,j]`: ê°™ì€ ì—´ì´ë©´ 1
- `manhattan_dist[i,j]`: ì •ê·œí™”ëœ Manhattan ê±°ë¦¬

```python
# ì ìš© ìœ„ì¹˜: spatial tokensë§Œ (CLS ì œì™¸)
attn[:, :, 1:, 1:] += Ï†(structural_bias)
```

### í•™ìŠµ ë°ì´í„° ìƒì„¸

| Source | Samples | ìš©ë„ |
|--------|---------|------|
| ChartQA train (augmented) | 28K | SFA fine-tuning |
| ChartQA train (human) | 7.3K | SFA fine-tuning |
| mllm_ready V3 | 5.5M rows | ì¶”í›„ Phase 3-4 |
| Cauldron | 41GB | ì¶”í›„ Phase 3-4 |

### ëª¨ë¸ êµ¬ì¡°

```
InternVL3.5-8B
â”œâ”€â”€ vision_model (InternViT-300M)
â”‚   â”œâ”€â”€ embeddings (patch_embed + pos_embed)
â”‚   â””â”€â”€ encoder
â”‚       â””â”€â”€ layers Ã— 24
â”‚           â”œâ”€â”€ attn â†’ SFAAttention (êµì²´)
â”‚           â”‚   â”œâ”€â”€ qkv (1024â†’3072)
â”‚           â”‚   â”œâ”€â”€ proj (1024â†’1024)
â”‚           â”‚   â””â”€â”€ structural_bias (NEW, 304 params)
â”‚           â”œâ”€â”€ mlp (1024â†’4096â†’1024)
â”‚           â””â”€â”€ layer_scale Ã— 2
â”œâ”€â”€ mlp1 (projector: 4096â†’4096)
â””â”€â”€ language_model (InternLM2.5-7B, frozen)
```
