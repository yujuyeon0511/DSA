# SFA Architecture Diagram AI Generation Prompt

> **ìš©ë„**: AI ë„êµ¬ (Claude, GPT-4o, Gemini ë“±)ì— ì…ë ¥í•˜ì—¬ ë…¼ë¬¸ Figure 2 (Architecture Diagram) ì´ˆì•ˆ ìƒì„±
> **ì¶œë ¥ í˜•ì‹**: SVG / TikZ / draw.io XML / Mermaid ì¤‘ íƒ1
> **ìµœì¢… ëª©í‘œ**: ECCV/CVPR ìˆ˜ì¤€ì˜ í•™ìˆ  ë…¼ë¬¸ ì•„í‚¤í…ì²˜ ê·¸ë¦¼

---

## Prompt (English â€” for AI diagram generation)

ì•„ë˜ í”„ë¡¬í”„íŠ¸ë¥¼ AIì— ê·¸ëŒ€ë¡œ ì…ë ¥í•˜ì„¸ìš”. í•„ìš”ì— ë”°ë¼ ì¶œë ¥ í˜•ì‹ì„ ì§€ì •í•˜ë©´ ë©ë‹ˆë‹¤.

---

### Main Prompt

```
Create a detailed, publication-quality architecture diagram for a research paper titled
"Structure-Factorized Attention for Document-Centric Multimodal LLMs".

The diagram should show the COMPLETE forward pass pipeline from input document image to
text output, with emphasis on the two novel modules: (1) Adaptive Density-Aware Tokenization
(ADAT) and (2) Structure-Factorized Attention (SFA).

============================================================
OVERALL PIPELINE (left-to-right flow):
============================================================

The diagram flows LEFT â†’ RIGHT through these major stages:

[Input Image] â†’ [Density Estimator] â†’ [Adaptive Patch Tokenization] â†’ [Vision Encoder w/ SFA] â†’ [Pixel Shuffle + MLP Projector] â†’ [LLM] â†’ [Text Output]

Use a clean, horizontal layout. Each major block should be a rounded rectangle.
Draw data flow arrows between blocks with tensor shape annotations on each arrow.

============================================================
STAGE 1: INPUT
============================================================

- Show a small document/chart image thumbnail (448Ã—448 px)
- Label: "Document Image"
- Tensor annotation on output arrow: "(B, 3, 448, 448)"

============================================================
STAGE 2: DENSITY ESTIMATOR (Novel Module â€” highlight with AMBER border #F9AB00)
============================================================

This is a lightweight CNN that predicts text density.

Internal structure (show as a vertical stack inside a dashed box):
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Text Density Estimator (186K params)   â”‚
  â”‚                                         â”‚
  â”‚  Conv2d(3â†’32, k=3, s=2) + BN + ReLU    â”‚  448â†’224
  â”‚  Conv2d(32â†’64, k=3, s=2) + BN + ReLU   â”‚  224â†’112
  â”‚  Conv2d(64â†’128, k=3, s=2) + BN + ReLU  â”‚  112â†’56
  â”‚  Conv2d(128â†’64, k=3, s=2) + BN + ReLU  â”‚  56â†’28
  â”‚  Conv2d(64â†’32, k=3, s=1) + BN + ReLU   â”‚  28â†’28
  â”‚  Conv2d(32â†’1, k=1) + Sigmoid           â”‚  28â†’28
  â”‚                                         â”‚
  â”‚  Output: D(x,y) âˆˆ [0,1]  (28Ã—28)       â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

- Input arrow: "(B, 3, 448, 448)" from the input image
- Output: Show a small density heatmap thumbnail (28Ã—28, use yellow-red gradient)
- The density map feeds into BOTH:
  (a) Adaptive Patch Tokenizer (determines patch sizes)
  (b) Block ID assignment for SFA (optional, via clustering)

============================================================
STAGE 3: ADAPTIVE PATCH TOKENIZATION (Novel Module â€” highlight with AMBER border)
============================================================

Show this as a branching process:

  Density Map D(x,y) â†’ Patch Size Assignment:
    - D > 0.7 (high density): 8Ã—8 patches  (small, more tokens)
    - 0.3 < D â‰¤ 0.7 (medium):  14Ã—14 patches (standard)
    - D â‰¤ 0.3 (low density):  32Ã—32 patches (large, fewer tokens)

  â†’ Token Budget Constraint: Î£ (s_kÂ² Ã— Area_k) â‰¤ N

Show a visual: the same document image with a multi-scale grid overlay where
dense text regions have finer grids and blank areas have coarser grids.

Output arrow annotation: "(B, N, D_vit)" where N â‰¤ 1024, D_vit = 1024

NOTE: For the baseline (current implementation), uniform 14Ã—14 patches are used,
producing 32Ã—32 = 1024 patches. The adaptive version is the proposed contribution.

============================================================
STAGE 4: VISION ENCODER WITH SFA (Core â€” highlight with BLUE border #1A73E8)
============================================================

This is InternViT-300M modified with SFA. Show it as a tall vertical stack of layers.

Header label: "InternViT-300M + SFA (24 Layers)"

Show the internal structure of ONE encoder layer in an expanded/zoomed view:

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚         InternVisionEncoderLayer (Ã—24)                â”‚
  â”‚                                                       â”‚
  â”‚   Input: (B, 1025, 1024)  [1 CLS + 32Ã—32 patches]   â”‚
  â”‚      â”‚                                                â”‚
  â”‚      â–¼                                                â”‚
  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
  â”‚   â”‚LayerNormâ”‚  (1024)                                 â”‚
  â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                         â”‚
  â”‚        â”‚                                              â”‚
  â”‚        â–¼                                              â”‚
  â”‚   â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—       â”‚
  â”‚   â•‘  Structure-Factorized Attention (SFA)      â•‘      â”‚
  â”‚   â•‘                                            â•‘      â”‚
  â”‚   â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â•‘      â”‚
  â”‚   â•‘  â”‚ QKV Linearâ”‚ (1024 â†’ 3072)              â•‘      â”‚
  â”‚   â•‘  â””â”€â”€â”¬â”€â”€â”€â”¬â”€â”€â”€â”¬â”˜                             â•‘      â”‚
  â”‚   â•‘     Q   K   V   each: (B, 16, 1025, 64)   â•‘      â”‚
  â”‚   â•‘     â”‚   â”‚                                  â•‘      â”‚
  â”‚   â•‘     â–¼   â–¼                                  â•‘      â”‚
  â”‚   â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â•‘      â”‚
  â”‚   â•‘  â”‚Content Attentionâ”‚  â”‚Structural Bias Ï† â”‚  â•‘      â”‚
  â”‚   â•‘  â”‚ QK^T / âˆšd      â”‚  â”‚                  â”‚  â•‘      â”‚
  â”‚   â•‘  â”‚(B,16,1025,1025)â”‚  â”‚(16, 1024, 1024)  â”‚  â•‘      â”‚
  â”‚   â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â•‘      â”‚
  â”‚   â•‘          â”‚         â•‹ ADD       â”‚            â•‘      â”‚
  â”‚   â•‘          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â•‘      â”‚
  â”‚   â•‘                    â–¼                        â•‘      â”‚
  â”‚   â•‘  S_ij = QK^T/âˆšd + Ï†(s_i, s_j)             â•‘      â”‚
  â”‚   â•‘  [spatial tokens only, CLS excluded]        â•‘      â”‚
  â”‚   â•‘                    â–¼                        â•‘      â”‚
  â”‚   â•‘              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                   â•‘      â”‚
  â”‚   â•‘              â”‚ Softmax  â”‚                   â•‘      â”‚
  â”‚   â•‘              â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜                   â•‘      â”‚
  â”‚   â•‘                   â–¼                         â•‘      â”‚
  â”‚   â•‘          Attn Ã— V â†’ Proj (1024â†’1024)        â•‘      â”‚
  â”‚   â•‘                                            â•‘      â”‚
  â”‚   â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•       â”‚
  â”‚        â”‚                                              â”‚
  â”‚        Ã— LayerScale (ls1)                              â”‚
  â”‚        â”‚                                              â”‚
  â”‚   â”€â”€â”€â”€â”€â”¤ (+) Residual â—„â”€â”€â”€â”€â”€ Input                    â”‚
  â”‚        â”‚                                              â”‚
  â”‚        â–¼                                              â”‚
  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                         â”‚
  â”‚   â”‚LayerNormâ”‚                                         â”‚
  â”‚   â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜                                         â”‚
  â”‚        â–¼                                              â”‚
  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
  â”‚   â”‚ MLP (FFN)                â”‚                        â”‚
  â”‚   â”‚ Linear(1024â†’4096) â†’ GELU â”‚                        â”‚
  â”‚   â”‚ Linear(4096â†’1024)        â”‚                        â”‚
  â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
  â”‚        Ã— LayerScale (ls2)                              â”‚
  â”‚        â”‚                                              â”‚
  â”‚   â”€â”€â”€â”€â”€â”¤ (+) Residual â—„â”€â”€â”€â”€â”€ LayerNorm output         â”‚
  â”‚        â”‚                                              â”‚
  â”‚   Output: (B, 1025, 1024)                              â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

============================================================
STAGE 4-DETAIL: STRUCTURAL BIAS Ï†(s_i, s_j) â€” ZOOMED INSET
============================================================

Show a separate detailed inset box (connected by a dashed line to the Ï† block above)
explaining the structural bias computation:

  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
  â•‘  Structural Bias Ï†(s_i, s_j)  [304 params per layer]   â•‘
  â•‘                                                         â•‘
  â•‘  Ï† = w_row Â· ğŸ™[row_i = row_j]       â† Same-Row Bias   â•‘
  â•‘    + w_col Â· ğŸ™[col_i = col_j]       â† Same-Column Biasâ•‘
  â•‘    + w_dist Â· (-manhattan(i,j))      â† Distance Decay  â•‘
  â•‘    + block_embed(b_i)áµ€ block_embed(b_j) â† Block Sim   â•‘
  â•‘                                                         â•‘
  â•‘  Parameters:                                            â•‘
  â•‘    w_row:  (16,)     â† per-head, init N(0, 0.02)       â•‘
  â•‘    w_col:  (16,)     â† per-head, init N(0, 0.02)       â•‘
  â•‘    w_dist: (16,)     â† per-head, init N(0, 0.02)       â•‘
  â•‘    block_embed: Embedding(16 blocks, 16 heads)          â•‘
  â•‘                                                         â•‘
  â•‘  Precomputed buffers (32Ã—32 grid):                      â•‘
  â•‘    same_row:      (1024, 1024)  binary indicator        â•‘
  â•‘    same_col:      (1024, 1024)  binary indicator        â•‘
  â•‘    manhattan_dist: (1024, 1024) normalized [0,1]        â•‘
  â•‘                                                         â•‘
  â•‘  Applied to: attn[:, :, 1:, 1:]  (spatial tokens only)  â•‘
  â•‘  CLS token: no structural bias applied                  â•‘
  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Alongside this box, show 4 small matrix heatmaps (conceptual):
  [Row Bias]  [Col Bias]  [Distance]  [Combined Ï†]
Each should be a 32Ã—32 thumbnail with intuitive patterns:
  - Row Bias: horizontal bands (same-row patches highlighted)
  - Col Bias: vertical bands (same-column patches highlighted)
  - Distance: radial gradient from center (closer = stronger)
  - Combined: grid-like pattern with both row and column structure

============================================================
STAGE 5: PIXEL SHUFFLE DOWNSAMPLING + MLP PROJECTOR
============================================================

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Feature Extraction & Projection                   â”‚
  â”‚                                                    â”‚
  â”‚  1. Remove CLS token                               â”‚
  â”‚     (B, 1025, 1024) â†’ (B, 1024, 1024)             â”‚
  â”‚                                                    â”‚
  â”‚  2. Reshape to spatial grid                        â”‚
  â”‚     (B, 1024, 1024) â†’ (B, 32, 32, 1024)           â”‚
  â”‚                                                    â”‚
  â”‚  3. Pixel Shuffle (downsample_ratio=0.5)           â”‚
  â”‚     (B, 32, 32, 1024) â†’ (B, 16, 16, 4096)         â”‚
  â”‚     [4Ã— spatial reduction, 4Ã— channel expansion]   â”‚
  â”‚                                                    â”‚
  â”‚  4. Flatten to sequence                            â”‚
  â”‚     (B, 16, 16, 4096) â†’ (B, 256, 4096)            â”‚
  â”‚                                                    â”‚
  â”‚  5. MLP Projector (mlp1):                          â”‚
  â”‚     LayerNorm(4096)                                â”‚
  â”‚     â†’ Linear(4096, 4096) â†’ GELU                   â”‚
  â”‚     â†’ Linear(4096, 4096)                           â”‚
  â”‚     Output: (B, 256, 4096)                         â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Output arrow: "(B, 256, 4096) â€” 256 visual tokens"

============================================================
STAGE 6: LANGUAGE MODEL (LLM)
============================================================

  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
  â”‚  Qwen3-8B (Frozen)                      â”‚
  â”‚                                         â”‚
  â”‚  36 Transformer Layers                  â”‚
  â”‚  hidden_size = 4096                     â”‚
  â”‚  32 attention heads (GQA, 8 KV heads)   â”‚
  â”‚  head_dim = 128                         â”‚
  â”‚  FFN intermediate = 12288               â”‚
  â”‚  Activation: SiLU                       â”‚
  â”‚  Vocab: 151,936                         â”‚
  â”‚                                         â”‚
  â”‚  Input: [System] [Visual Tokens] [Query]â”‚
  â”‚         â†‘                               â”‚
  â”‚    256 visual tokens embedded at 4096   â”‚
  â”‚    replace <IMG_CONTEXT> placeholders   â”‚
  â”‚                                         â”‚
  â”‚  FROZEN â€” no gradient flows back        â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

  â†’ Output: "6.12%"  (text answer to the question)

============================================================
TRAINABLE vs FROZEN INDICATORS
============================================================

Use visual cues to distinguish trainable and frozen components:
  - TRAINABLE: Solid border, filled background (light blue tint)
    â†’ Density Estimator (186K params)
    â†’ Vision Encoder attention layers (SFA: 7,296 new params + 300M pretrained)
    â†’ MLP Projector mlp1
  - FROZEN: Dashed border, gray background
    â†’ LLM (Qwen3-8B, ~8B params)

Show a small legend:
  â–  Trainable (4.0% of total)  â–¡ Frozen (96.0%)
  â˜… Novel module (SFA / ADAT)

============================================================
COLOR SCHEME
============================================================

Use these exact colors for consistency with the paper:
  - SFA / Ours blocks:    #1A73E8 (Research Blue) â€” borders and highlights
  - Structural bias Ï†:    #00897B (Structural Teal) â€” Ï† inset box
  - Density / ADAT:       #F9AB00 (Density Amber) â€” density estimator border
  - Baseline / Standard:  #70757A (Neutral Slate) â€” frozen LLM, standard layers
  - Background:           #F8F9FA (Paper White) â€” clean white background
  - Text / Labels:        #202124 (Charcoal) â€” all text and arrows
  - Tensor annotations:   #5F6368 (gray) â€” shape labels on arrows

============================================================
STYLE GUIDELINES
============================================================

  - Academic publication quality (ECCV/CVPR style)
  - Clean, minimal design with NO unnecessary decoration
  - Font: sans-serif (Arial or Helvetica)
  - Font size: Module names 11pt, tensor shapes 8pt, math 10pt
  - Arrow style: thin solid lines with arrowheads
  - Module boxes: rounded corners (4px radius), thin borders (1pt)
  - Novel modules: slightly thicker border (2pt) in their designated color
  - Mathematical notation rendered properly: subscripts, superscripts, âˆšd
  - Aspect ratio: approximately 3:1 (wide landscape for double-column paper)
  - Total width should fit a double-column figure (~6.875 inches)

============================================================
EQUATION TO INCLUDE IN THE DIAGRAM
============================================================

Place this equation prominently near the SFA block:

  S_ij = (Q_i Â· K_j^T) / âˆšd  +  Ï†(s_i, s_j)
         \_____________/         \____________/
          Content Attn         Structural Bias

============================================================
PARAMETER SUMMARY (include as a small table or annotation)
============================================================

| Component            | New Params  | Note              |
|----------------------|-------------|-------------------|
| Density Estimator    | 186K        | Lightweight CNN   |
| SFA Bias (per layer) | 304         | w_row+w_col+w_dist+block_embed |
| SFA Total (24 layers)| 7,296       | 0.002% of model   |
| Trainable Total      | 337.6M      | 4.0% of 8.5B      |
```

---

## TikZ ë²„ì „ ìš”ì²­ ì‹œ ì¶”ê°€ í”„ë¡¬í”„íŠ¸

```
Generate TikZ/LaTeX code for this architecture diagram.
Use the following TikZ libraries: positioning, arrows.meta, fit, calc, backgrounds, shapes.geometric
Define custom colors matching the hex codes above.
Use \footnotesize for tensor annotations and \small for module names.
The diagram should compile with pdflatex without errors.
```

---

## Mermaid ë²„ì „ ìš”ì²­ ì‹œ ì¶”ê°€ í”„ë¡¬í”„íŠ¸

```
Generate a Mermaid diagram (flowchart LR) for this architecture.
Use subgraphs for each major stage.
Add notes for tensor shapes.
Style novel modules with the specified colors.
```

---

## draw.io XML ìš”ì²­ ì‹œ ì¶”ê°€ í”„ë¡¬í”„íŠ¸

```
Generate draw.io compatible XML for this architecture diagram.
Use proper styling with the color scheme above.
Group related components.
Make it editable for fine-tuning the layout.
```

---

## ì£¼ì˜ì‚¬í•­

1. **ì‹¤ì œ êµ¬í˜„ê³¼ ì¼ì¹˜í•´ì•¼ í•˜ëŠ” ìˆ˜ì¹˜**:
   - InternViT: 24 layers, dim=1024, 16 heads, head_dim=64, patch=14, image=448
   - Grid: 32Ã—32 = 1024 patches + 1 CLS = 1025 tokens
   - Pixel Shuffle: 32Ã—32Ã—1024 â†’ 16Ã—16Ã—4096 â†’ flatten â†’ 256 tokens
   - MLP Projector: LayerNorm(4096) â†’ Linear(4096â†’4096) â†’ GELU â†’ Linear(4096â†’4096)
   - LLM: Qwen3-8B, 36 layers, dim=4096, 32 heads (GQA 8 KV), FFN=12288
   - SFA bias: 304 params/layer (w_row:16 + w_col:16 + w_dist:16 + block_embed:16Ã—16=256)

2. **SFA ì ìš© ìœ„ì¹˜**: InternViT ë‚´ë¶€ì˜ ê° layer attention (24ê°œ ì „ë¶€)
   - CLS í† í°(index 0)ì—ëŠ” structural bias ë¯¸ì ìš©
   - spatial tokens (index 1~1024)ì—ë§Œ ì ìš©: `attn[:, :, 1:, 1:] += Ï†`

3. **Density Estimator**:
   - ë³„ë„ CNN (InternViT ì™¸ë¶€), self-supervised í•™ìŠµ
   - ì¶œë ¥ density mapì€ ADATì— ì‚¬ìš© (patch size ê²°ì •)
   - ë˜í•œ block_id ìƒì„±ì—ë„ í™œìš© ê°€ëŠ¥ (clustering â†’ SFAì˜ block bias)

4. **í•™ìŠµ ì „ëµ**:
   - Stage 1: Density Estimator ë…ë¦½ í•™ìŠµ (MSE loss, pseudo label)
   - Stage 2: Vision Encoder (SFA injected) + Projector fine-tuning (LLM frozen)
   - Stage 3: SCR loss ì¶”ê°€ fine-tuning (L_entropy + L_grounding + L_stability)

5. **ë…¼ë¬¸ Figure 2ì™€ì˜ ê´€ê³„**:
   - ì´ ë‹¤ì´ì–´ê·¸ë¨ì´ Figure 2ì˜ ì™„ì„±ë³¸
   - ì™¼ìª½: ì…ë ¥ â†’ ì¤‘ê°„: í•µì‹¬ ëª¨ë“ˆ (ADAT, SFA) â†’ ì˜¤ë¥¸ìª½: ì¶œë ¥
   - SFA ë‚´ë¶€ ìˆ˜ì‹ zoomed insetì´ í•µì‹¬ ê¸°ì—¬ë¥¼ ì‹œê°ì ìœ¼ë¡œ ê°•ì¡°
